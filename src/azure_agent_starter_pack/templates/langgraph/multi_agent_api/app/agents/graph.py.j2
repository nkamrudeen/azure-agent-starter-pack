"""LangGraph state graph: multi-agent workflow with tool nodes."""

import os
from typing import Annotated, TypedDict

from langchain_core.messages import BaseMessage
from langchain_openai import AzureChatOpenAI
from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

from app.tools.search_tool import search_tool


class AgentState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]


def _get_llm() -> AzureChatOpenAI:
    return AzureChatOpenAI(
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT", ""),
        azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT", "gpt-4o"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview"),
    )


def _should_continue(state: AgentState) -> str:
    last = state["messages"][-1]
    if hasattr(last, "tool_calls") and last.tool_calls:
        return "tools"
    return END


def _agent_node(state: AgentState) -> AgentState:
    llm = _get_llm()
    llm_with_tools = llm.bind_tools([search_tool])
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}


def build_graph() -> StateGraph:
    """Build and compile the LangGraph state graph."""
    tools = [search_tool]
    tool_node = ToolNode(tools)

    graph = StateGraph(AgentState)
    graph.add_node("agent", _agent_node)
    graph.add_node("tools", tool_node)

    graph.set_entry_point("agent")
    graph.add_conditional_edges("agent", _should_continue, {"tools": "tools", END: END})
    graph.add_edge("tools", "agent")

    return graph.compile()
