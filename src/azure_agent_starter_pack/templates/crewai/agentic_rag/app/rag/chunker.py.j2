"""Document chunker: split documents into overlapping chunks for indexing."""

from langchain_text_splitters import RecursiveCharacterTextSplitter

from app.rag.config import CHUNK_OVERLAP, CHUNK_SIZE


def chunk_text(text: str, metadata: dict | None = None) -> list[dict]:
    """Split text into chunks with metadata.

    Returns a list of dicts with 'content' and 'metadata' keys,
    ready for embedding and indexing.
    """
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", ". ", " ", ""],
    )
    chunks = splitter.split_text(text)
    return [
        {
            "content": chunk,
            "metadata": {**(metadata or {}), "chunk_index": i},
        }
        for i, chunk in enumerate(chunks)
    ]


def chunk_pdf(pdf_path: str) -> list[dict]:
    """Extract text from a PDF and chunk it."""
    from pypdf import PdfReader

    reader = PdfReader(pdf_path)
    pages = []
    for i, page in enumerate(reader.pages):
        text = page.extract_text() or ""
        if text.strip():
            pages.append({"text": text, "page": i + 1})

    all_chunks = []
    for page_info in pages:
        chunks = chunk_text(
            page_info["text"],
            metadata={"source": pdf_path, "page": page_info["page"]},
        )
        all_chunks.extend(chunks)
    return all_chunks
